\section{Background}

In order to obtain the execution semantics of a multi-threaded program on a
multi-processor system, one has to understand the memory consistency model of
the underlying system. This is necessary because, as opposed to a direct access
to a single-ported memory, the processors a) have store buffers which reorders
the sequence of memory requests from the processor, for faster access (say by
bypassing a store-value to a subsequent load request), and b) communicate with
the memory through several levels of data caches for faster access. The memory
consistency model describes the semantic behavior of such requests and the
system ensures that the cache hierarchy and the store buffers do not violate
the specified semantics.

Memory consistency models can be partitioned into two sub-parts
\cite{Arvind-memory-model}: a) the ``global'' store-atomicity property for each
location/address and b) the ``local'' reordering restrictions between requests
to different locations within each processor. The store-atomicity property per
address can be informally explained as follows: each location behaves like an
atomic register in which no two writes (stores) to that location can happen
simultaneously, and any read of that location (load) returns the previously
written value in that location. Most memory consistency models require that the
memory subsystem obeys the store-atomicity property. The reordering
restrictions dictated by the memory consistency model pertain to reordering
requests within the same processor (unlike the store-atomicty property which is
global across the entire system), but across multiple addresses. For example,
it dictates whether a store request to an address $x$ can be issued to the
memory sub-system before a load request to a different address $y$, which was
generated by the same processor earlier (\ie load $y$ happened before store $x$
is program order, but the order of issue to memory sub-system is reversed).

The mechanism employed by the memory sub-system to ensure store-atomicity per
location, in the presence of caches, is known as \emph{cache coherence}. In the
absence of caches, since there is exactly one copy of the data for each
address, it is easy to ensure cache coherence. The problem comes in the
presence of shared caches -- multiple copies of the same address can exist in
different caches, and if these locations are independently written, then the
same address can end up having different values in two different caches. Each
location would no longer behave like an atomic register unless some sort of
co-ordination happens between the different caches -- this co-ordination is
summed up as the \emph{cache coherence protocol}.

\subsection{Formal definition of store-atomicity}
In this section we give the formal definition of the store-atomicity property.

The requests issued by the processors to the memory subsystem can be modeled
using a function \reqFn. $\reqFn(p, i)$ returns the $i^{th}$ request issued by
processor $p$, \ie $\reqFn: (\textit{Processor} * \mathbb{N}) @-> \Request$.
The processor name and the position of the request within the processor
uniquely identifies the request.  Figure \ref{req-resp} shows the data-type
corresponding to a request issued from the processor to the memory subsystem.
A request contains the address (\addrQ) corresponding to the request, and a
type indicating whether the request is a load or a store (\desc). In case of a
store request, it also contains data (\dataQ) supplied by the processor for
that address.

Figure \ref{req-resp} also shows the data-type corresponding to a response
issued from the memory subsystem to the processor.  A response contains a label
(\labelR) to identify the request corresponding to the response. The label
contains a processor name and a position, which uniquely identifies a request.
In the case of a load request, the memory sub-system returns \dataR, the data
returned by the memory subsystem for that address. The memory sub-system also
returns a natural number, \timeR, which is used solely in the definition of
store atomicity, and is not returned in a real system. \timeR{} can be informally
thought to represent the position at which this request has been handled
globally among all the requests issued from all the processors.

\begin{figure}
\centering
\begin{subfigure}{5.5cm}
\begin{tabular}{|lp{4.5cm}|}
\hline
\multicolumn{2}{|c|}{\Request}\\
\hline
\addrQ:& Address associated with the request\\
\desc:& Request type (\Ld{} or \St)\\
\dataQ:& Data associated with a \St{} request\\
\hline
\end{tabular}
\end{subfigure}~~~~
\begin{subfigure}{5.5cm}
\begin{tabular}{|lp{4.5cm}|}
\hline
\multicolumn{2}{|c|}{\Response}\\
\hline
\labelR:& Label identifying the request corresponding to this response\\
\dataR:& Data returned by the memory subsystem for a \Ld{} request\\
\timeR:& Natural number representing global order of (processing) requests\\
\hline
\end{tabular}
\end{subfigure}
\caption{Data types for request and response}
\label{req-resp}
\end{figure}

In the following, a \Response{} set only contains those responses sent by the
memory subsystem.

The responses should obey the following sanity conditions:

\begin{defn} (The labels in the responses are unique. Since \dataR{} field is
irrelevant for store requests, so uniqueness of responses does not depend on
\dataR{} field for stores.)
\begin{multline*}
\textit{uniqRespLabels} := \forall (r_1, r_2 \in \Response),\\
r_1.\labelR = r_2.\labelR @-> r_1.\timeR = r_2.\timeR \wedge\\
(\reqFn(r_1.\labelR) = \Ld @-> r_1.\dataR = r_2.\dataR)
\end{multline*}
\end{defn}

\begin{defn} (No response can share the same time as another store response.)
\begin{multline*}
\textit{uniqStRespTimes} := 
\forall (r_1, r_2 \in \Response),
r_1.\timeR = r_2.\timeR @-> \\
(\reqFn (r_1.\labelR)).\addrQ = (\reqFn (r_2.\labelR)).\addrQ @->\\
(\reqFn (r_1.\labelR)).\desc = \St @->
r_1.\labelR = r_2.\labelR
\end{multline*}
\end{defn}

In addition, the global ordering of responses to the same processor should not
violate the local ordering of the corresponding requests.
\begin{defn}
\begin{multline*}
\textit{localOrdering} :=
\forall (r_1, r_2 \in \Response), (r_1.\labelR).\fst = (r_2.\labelR).\fst @->\\
(r_1.\labelR).\snd < (r2.\labelR).\snd @-> r_1.\timeR \le r_2.\timeR
\end{multline*}
\end{defn}

This brings us to the main condition for store atomicity which states that the
value returned for a load response corresponds to the \emph{last earlier} store
request that has been processed in the system for that address
(\textit{lastEarlierValue}). The \emph{last} and \emph{earlier} are defined
according to the field \timeR{} returned in the responses. In case no store has
happened earlier for a particular address when a load is processed, then the
load response returns the initial value for the address (\textit{initialValue}).
\begin{defn}
\begin{multline*}
\textit{initialValue} (r: \Response) := \mylet q := \reqFn (r.\labelR) \myin\\
q.\desc = \Ld @-> r.\dataR = \initData (r.\addrQ) \wedge \\
\forall (r' \in \Response), \mylet q' := \reqFn (r'.\labelR) \myin 0 \le r'.\timeR < r.\timeR @->\\
\neg (q'.\addrQ = q.\addrQ \wedge q'.\desc = \St)
\end{multline*}
\end{defn}

\begin{defn}
\begin{multline*}
\textit{lastEarlierValue} (r: \Response) := \mylet q := \reqFn (r.\labelR) \myin\\
q.\desc = \Ld @-> \exists r_m, \mylet q_m := \reqFn (r_m.\labelR) \myin\\
r.\dataR = q_m.\dataQ \wedge
\forall (r' \in \Response), \mylet q' := \reqFn (r'.\labelR) \myin \\ r_m.\timeR \le r'.\timeR < r.\timeR @->
\neg (q'.\addrQ = q.\addrQ \wedge q'.\desc = \St)
\end{multline*}
\end{defn}

Using the above definitions, we can define the store-atomicity theorem as follows:
\begin{thm}
\begin{multline*}
storeAtomicity := 
\textit{uniqRespLabels} \wedge
\textit{uniqStRespTimes} \wedge \textit{localOrdering}\\ \wedge 
(\forall (r \in \Response), \textit{initialValue}(r) \vee \textit{lastEarlierValue}(r))
\end{multline*}
\end{thm}
