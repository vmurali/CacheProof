\section{Correctness of a Cache Coherence Protocol}
\label{Sec:Background}

Before we can discuss our protocol and proof framework, we must first establish
exactly what it means for a cache coherence protocol to be correct. 

Intuitively, the simplest view of shared memory is as a memory (array of addressible objects)
multiplexed amongst the many individual clients/processors, which send read/write
messages to the memory as needed. In
this view, all operations in the system appear to have a single unique total
ordering.

All modern systems have caches between the processor and memory for faster
memory access.  It is often also useful to permit some reorderings of requests
from a processor to the memory to improve performance.  For instance, in the
context of a processor with local store buffer, we may wish to allow a store to
bypass a subsequent load request to a different location. The specification of
which reorderings are permitted or restricted defines the memory consistency
model.

Most memory consistency models can be partitioned into two
parts~\cite{Arvind-memory-model}: (a) a ``global'' store-atomicity property
stating that for each location/address in memory, every read and write access
to that location occurs in some total order, with each operation seeing the
effects of previous operations and not later ones (in other words, each
location behaves like an atomic register) and (b), a ``local'' reordering
restriction between requests to different locations within each processor.
Changing the memory model by modifying the reordering restrictions will not
incur a reverification of the store-atomicity property.

The mechanism employed by the memory subsystem to ensure store-atomicity per
location, in the presence of caches, is known as \emph{cache coherence}. In the
presence of caches, multiple copies of the same address can exist in different
caches. If these copies are written independently, the same address can end up
having different values in different caches, violating the atomic register-like
behavior unless the caches coordinate via a \emph{cache coherence protocol}.

\subsection{Formal Definition of Store Atomicity}
We will model an abstract memory subsystem, which interfaces with a set of
processors. The requests issued by the processors to the memory subsystem can
be modeled using a function \reqFn, where $\reqFn(p, i)$ is the $i^{th}$ request
issued by processor $p$.

%Figure~\ref{req-resp} shows the
%data-type corresponding to a request issued from the processor to the
%memory subsystem.

We define a record type modeling a request in terms of a set of named fields.
A request contains the address (\addrQ) corresponding to the request, as well as a
\desc{} indicating whether the request is a load or a store. A store request
also contains the data supplied by the processor for that address (\dataQ). A
response (modeled with a different record type) contains a label (\labelR)
to identify the request uniquely, via a pair of a processor name and a processor-local
sequence number.  In the case of a load request, the memory
subsystem returns \dataR, the data returned by the memory subsystem for that
address. The memory subsystem also returns $\timeR \in \mathbb{N}$, which
intuitively represents the time at which the request is handled among the
global set of handled requests from all the processors. The \timeR{} field is
present solely as a specificational device to capture store atomicity, and it
would not be present in a running system implementation.

%We model request of a processor formally with the function
%\reqFn. $\reqFn(p, i)$ returns the $i^{th}$ request issued by
%processor $p$, \ie{} $\reqFn: (\textit{Processor} * \mathbb{N}) @->
%\Request$.  The processor name and the position of the request within
%the processor uniquely identifies a request.

%\begin{figure}
%\centering
%\begin{subfigure}{5.5cm}
%\begin{tabular}{|lp{4.5cm}|}
%\hline
%\multicolumn{2}{|c|}{\Request}\\
%\hline
%\addrQ:& Address associated with the request\\
%\desc:& Request type (\Ld{} or \St)\\
%\dataQ:& Data associated with a \St{} request\\
%\hline
%\end{tabular}
%\end{subfigure}~~~~
%\begin{subfigure}{5.5cm}
%\begin{tabular}{|lp{4.5cm}|}
%\hline
%\multicolumn{2}{|c|}{\Response}\\
%\hline
%\labelR:& Label identifying the request corresponding to this response\\
%\timeR:& Natural number representing global order of (processing) requests\\
%\dataR:& Data returned by the memory subsystem for a \Ld{} request\\
%\hline
%\end{tabular}
%\end{subfigure}
%\caption{Data types for request and response}
%\label{req-resp}
%\end{figure}

We model a single protocol execution as a set of all the requests and responses
that sent in the course of that execution.
The fundamental parameter is a (potentially infinite) set \Response{} of all responses
that the memory sends to processors.  From here, the associated requests follow by
applying the function $\reqFn$ to map each response to the request that provoked it.
Responses should obey the following sanity conditions. 
\begin{defn} (No label is reused across multiple distinct responses.)
%Since \dataR{} field is
%irrelevant for store requests, so uniqueness of responses does not depend on
%\dataR{} field for stores.)
\small
\begin{multline*}
\textit{uniqRespLabels} := \forall (r_1, r_2 \in \Response),\\
r_1.\labelR = r_2.\labelR @-> r_1.\timeR = r_2.\timeR \wedge\\
(\reqFn(r_1.\labelR) = \Ld @-> r_1.\dataR = r_2.\dataR)
\end{multline*}
\label{uniqRespLabels}
\end{defn}

\begin{defn} (No response can share a \timeR{} value with another store response.)
\small
\begin{multline*}
\textit{uniqStTimes} := 
\forall (r_1, r_2 \in \Response),
r_1.\timeR = r_2.\timeR @-> \\
\reqFn (r_1.\labelR).\addrQ = \reqFn (r_2.\labelR).\addrQ @->\\
\reqFn (r_1.\labelR).\desc = \St @->
r_1.\labelR = r_2.\labelR
\end{multline*}
\label{uniqStTimes}
\end{defn}

In addition, the global ordering of responses to the same processor should not
violate the local ordering of the corresponding requests.

\begin{defn}
\small
\begin{multline*}
\textit{localOrdering} :=
\forall (r_1, r_2 \in \Response), r_1.\labelR.\fst = r_2.\labelR.\fst @->\\
r_1.\labelR.\snd < r2.\labelR.\snd @-> r_1.\timeR \le r_2.\timeR
\end{multline*}
\label{localOrdering}
\end{defn}

This brings us to the main condition for store atomicity, which states that the
data returned for a load response corresponds to the \emph{last earlier} store
request from any processor that has been handled for that address,
\emph{last} and \emph{earlier} being defined according to the field \timeR{}
returned in the responses.  This proposition is indicated by
\textit{lastEarlierValue}$(a, t, d)$ for a load request for address $a$ handled
at time $t$, returning data $d$.  In case no store has happened earlier for a
particular address when a load is processed, then the load response returns the
initial value for the address, the whole proposition indicated by
\textit{initialValue}$(a, t, d)$.
\begin{defn}
\small
\begin{multline*}
\textit{initialValue}(a, t, d) := d = \initData (a) \; \wedge \\
\forall (r' \in \Response), 0 \le r'.\timeR < t @->\\
\neg (\reqFn (r'.\labelR).\addrQ = a \wedge \reqFn (r'.\labelR).\desc = \St)
\end{multline*}
\label{initialValue}
\end{defn}

\begin{defn}
\small
\begin{multline*}
\textit{lastEarlierValue}(a, t, d) := \exists (r_m \in \Response),\\ \reqFn (r_m.\labelR).\dataQ = d \wedge 
\reqFn (r_m.\labelR).\desc = \St \; \wedge\\ \reqFn (r_m.\labelR).\addrQ = a \wedge
\forall (r' \in \Response), r_m.\timeR < r'.\timeR < t @->\\
\neg (\reqFn (r'.\labelR).\addrQ = a \wedge \reqFn (r'.\labelR).\desc = \St)
\end{multline*}
\label{lastEarlierValue}
\end{defn}

Using the above definitions, we can define the store atomicity theorem as follows:
\begin{thm}
\small
\begin{multline*}
\textit{storeAtomicity} := 
\textit{uniqRespLabels} \wedge
\textit{uniqStTimes} \wedge \textit{localOrdering} \; \wedge \\
(\forall (r \in \Response), \mylet q := \reqFn(r.\labelR) \myin q.\desc = \Ld \; @-> \\
(\textit{initialValue}(q.\addrQ, r.\timeR, r.\dataR) \vee \textit{lastEarlierValue}(q.\addrQ, r.\timeR, r.\dataR)))
\end{multline*}
\label{storeAtomicity}
\end{thm}

The technical meat of this paper is a framework for proving this store atomicity
property for a whole family of cache coherence protocols, based on parameterization
points corresponding to key architectural choices.
