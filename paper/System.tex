\section{System}
\label{sec:System}

The system we are considering consists of a tree hierarchy of caches. These
caches are inclusive, \ie a cache at a higher level (near the root) contains
all the addresses present in caches in the lower levels of its substree. The
root of the communicates with the main memory, and the leaf caches communicate
with the processor (Figure \ref{hier}).

Each cache has a \emph{coherence state} associated with each address. The
coherence state can be one of the three values: \Mo{} (Modified), \Sh{} (Shared) or
\In{} (Invalid). \Mo{} state denotes that the subtree rooted at the cache in \Mo{}
state for that address can modify the data, \ie{} both read and write the data
corresponding to the address. \Sh{} state denotes that the subtree rooted at the
cache in \Sh{} state for that address can only read the data corresponding to
that address and \In{} state denotes that the subtree rooted at the cache in \In{}
state can neither read nor write the data corresponding to the address. The
meanings of the state is clear, but one must verify the actual cache coherence
protocol for violations of these invariants, which is what the proof in this
paper intends to do. There's a logical ordering between the states, in terms of
the permissions that they have: $\Mo > \Sh > \In$ (the notation should be read
assuming that the order is transitively closed).
In addition, each non-leaf cache maintains a \emph{directory}, which contains a
local version of the state of each of its children for a particular address.
This local version may be stale, but it should not be lower than the real state
of the child (again this property has to be proven for a cache coherence
protocol).

Though this paper restricts the formal discussion to the simple MSI protocol,
extension of this proof technique as well as major portions of the proof to
other protocols like MOSI and MOESI is straightforward.

In order for a cache to change to a higher state for a given address, \ie
\emph{upgrade}, it has to \emph{request} its parents for increasing the state.
For a cache to change to a lower state, \ie \emph{downgrade}, it has to notify
its parents indicating the downgrade -- it uses \emph{response} messages for
this purpose. On the other end, for a parent to force a child to downgrade the
child's state for an address, or equivalently, to downgrade the parent's
directory state for the child, it has to \emph{request} that child to
downgrade, and a parent can notify a child about upgrading the child's state,
or equivalently, about upgrading the parent's directory state for the child, by
sending a \emph{response} message.

Each cache is connected to its parent cache using 3 logical connections: a)
\cpReq{} channel to transmit requests from the child to the parent, b) \cpResp{}
channel to transmit responses from the child to the parent, and c) \pc{}
\textbf{FIFO} channel to transmit both request and response messages from
parent to child. In addition, the leaf caches (called L1 caches usually)
communicate with the processor through two channels: a) \cproc{} \textbf{FIFO}
channel to transmit requests from the processor to L1 cache, and b) \procc{}
\textbf{FIFO} channel to transmit responses from the L1 cache to the processor.
There is exactly one of \cproc{} and \procc{} channels between the L1 and the processor.

In this paper, we will assume that each channel has a dedicated link between
caches. In a real system, these channels will be logically implemented over an
interconnect network, which poses additional problems that have to be proven --
namely that of deadlock and starvation-freedom. Though we have proved these
results requiring the network to obey very relaxed and practically feasible
conditions, we completely omit the formal discussion of deadlock and starvation
freedom in this paper because of lack of space. We \xxx{might later} informally
discuss how deadlock and starvation freedom properties are proved for our
system.

Since we have dedicated channel between each pair of child-parent, we will
index the three channels (\cpReq{}, \cpResp{} and \pc{}) by the name of the
child that uses that channel. We will also index the two channels (\cproc{} and
\procc{}) between the processor and L1 cache by the name of the L1 cache.

Figure \ref{format} shows the message format transmitted in the 3 channels
between caches. The messages transmitted between the processor and the L1 cache
is the same as in Figure \ref{req-resp} (except for the omission of the \proc{}
field, which is indicated by the channel's index).
\begin{figure}
\centering
\begin{tabular}{|l|lp{.9\textwidth}|}
\hline
\multirow{3}{*}{\cpReq} & \from: & Current state of child\\
& \myto: & Desired (higher) state of child\\
& \addr: & Address associated with the request\\
\hline
\multirow{4}{*}{\cpResp} & \from: & Current state of child\\
& \myto: & Downgraded state of child\\
& \addr: & Address associated with the request\\
& \data: & Data associated with the address, if necessary\\
\multirow{4}{*}{\pc} & \type: & \Req{} (for requests) and \Resp{} (for responses)\\
\hline
%& \from: & Current state of parent's directory for the child\\
& \myto: & Desired (lower) directory state of a child for \Req{} and upgraded
directory state of a child for \Resp{}\\
& \addr: & Address associated with the request\\
& \data: & Data associated with the address if necessary (for \Resp{} only)\\
\hline
\end{tabular}
\caption{Data types messages between caches}
\label{format}
\end{figure}

The description of the behavior of each of the caches can be given in terms of
``rules'' for state transitions. Each rule specifies a series of actions that
are performed atomically, and during the execution of a rule, no other
(conflicting) rule interferes with it. Thus, the behavior of any rule-based
system can be understood as if the rules executed one at a time.

Such a rule-based description can be automatically converted into synchronous
hardware, for instance using Bluespec \cite{Hoe:TCAD,HoeArvind:TRSSynthesis1}.
Bluespec executes each atomic rule into a single hardware cycle, which
simultaneously executing non-conflicting rules \ie{} rules that do not access the
same state (the exact conditions for simultaneous scheduling are specified in
the citations). Though the rules are logically executed atomically, their execution
can be spread across multiple cycles (as long as other conflicting rules are
not executed during the whole period of current rule's execution). Synchronous
hardware generation for multi-cycle atomic rules has also been studied
\cite{Karczmarek}.
