\section{Introduction} 

Large shared-memory multicores are likely to use cache-coherence protocols
which are directory based, hierarchical, and implemented using message passing.
Even though such protocols have been around for two decades (see, for example,
DASH\cite{DASH}, Alewife\cite{Anant}, ...) correct design and implementation of
such protocols remains a challenge. It is difficult to convince oneself that
all corner cases have been handled adequately without a formal proof. And yet
formal proofs of real implementations are practically non-existent. One can not
settle for conservative choices in cache-coherence protocol designs because
performance (\eg the number of messages needed to maintain coherence, the
buffer requirements, etc) is as important as correctness. Consequently proving
a simple protocol for a small number of caches, under unbounded buffer
assumption is of limited use in gaining confidence in the correctness of a real
protocol. 

In this paper we will consider systems where caches form a tree hierarchy and
caches are \emph{inclusive}, that is, if a cache contains address $a$ then its
parent is guaranteed to contain address $a$, though the parent may have stale
data for $a$. Every cache or node in the system has an associated directory
which contains information about its children caches. The coherence state
changes are orchestrated by passing messages in the form of \emph{upgrade} or
\emph{downgrade} requests and responses between the caches via the directory.
Unlike bus-based protocols which lock the bus till all the required state
transitions are done thereby ensuring atomicity of state transitions, in a
message-passing protocol, requests and responses are split leading to transient
states. This creates scenarios not present in bus-based protocols, which can
lead to coherence violations or deadlocks, if the protocol is not designed or
implemented carefully.

Several factors contribute to the difficulty of designing protocols for such
distributed, hierarchical and message-passing systems:

\begin{enumerate}

\item Lots of concurrent events must be dealt with without a central authority
to impose a sequence on events;

\item The state on which transitions are based is physically distributed in
space and cannot be accessed atomically;

\item Physical network may block the transmission of a message because of lack
of communication buffers or head-of-the-line blocking; 

\item For each message type, determining which cache and directory states are
possible and therefore must be dealt with is hard. An incomplete set of
transition rules may cause the protocol to deadlock.

\end{enumerate}

As examples of problems in designing correct protocols, we describe several
concrete and familiar scenarios from two-level systems (a private L1 cache for
each processor and a shared L2 cache):

\noindent \emph{Example 1:} A cache with a read permission for a line gets a
store request from its processor and hence, requires a write permission for
that line. The cache would send an upgrade request to the directory controller
and may eventually get a response from the directory controller. The response
would signify that the states in the other caches \emph{were} compatible with
this cache having write permission for the line. That is, the other caches
neither \emph{had} read nor write permissions for that line. But the messages
take time to propagate and the response message is necessarily based on the old
state bits (permissions) that the other caches had, not the permissions that
the other caches have at the moment the original cache gets the response. If
another cache gets a read or write permission for that line during the time the
messages are in flight, coherence would be violated.

\emph{Example 2:} A cache, already having read permission for a line, gets a
store request, and sends an upgrade request for write permission to the
directory controller. Instead of getting a response, the cache may receive a
request from the directory controller asking this cache to give up the read
permission for the line \ie an invalidate request. This could happen if the
directory controller received a request for write permission from another cache
earlier. It is not easy to determine the correct behavior of the cache
receiving the invalidate request -- whether it should ignore the invalidate
request and wait till it receives a response from the directory controller for
its request, or if it should invalidate its line. If it ignores the invalidate
request, is there any guarantee that it would receive a response for its
request for write permission, or would it deadlock?

\emph{Example 3:} A cache receives an invalidate request from the directory
controller for a line that is not present in the cache. Is such a request even
possible? The directory does not have access to the up-to-date state of the
cache, and so can potentially make this request. How should a cache handle this
request; should it drop such a request, or respond saying that it does not have
the line?

These examples give a glimpse of the complexity of designing and implementing a
correct cache coherence protocol in a message-passing directory-based setting.
Even for a 2-level cache hierarchy, designing and implementing the protocol is
very hard. This problem is greatly exacerbated in a multi-level cache
hierarchy, which is becoming the norm because of the increasing core counts. 

In this paper, we present a substantially easier method to design
cache-coherence protocols for such systems. The method essentially breaks down
the design problem in two parts: a part that is an abstract protocol shared by
a number of concrete protocols, and another part that is specific to the
protocol to be designed and implemented. The abstract protocol is parameterized
by the number of cache levels and the number of caches in each level of the
hierarchy as well as by a predicate which involves a local ``compatibility of
state'' test. We illustrate our methodology by designing multiple
hierarchical cache-coherence protocols, notably MSI, MESI, MOSI, MOESI, both in
the presence as well as in the absence of point-to-point FIFO networks.

Our method substantially reduces the design and proof burden for new protocols
because of the common abstract protocol. The abstract protocol is a set of
transitions that the caches and directories follow to send or receive a request
or a response. We have formally proved that these transitions ensure the
following properties: a) the directory's notion of a cache's state is
``conservative'' in that a cache is never going to have more permissions that
what the directory thinks the cache has; and b) any request will eventually get
a corresponding response. A formal proof of the abstract protocol was written
using the Coq theorem prover \cite{}, however, a discussion of the formal proof
is beyond the scope of this paper.

It should be noted that the flexibility of our methodology to design multiple
cache coherence protocols comes from the fact that we do not assign any meaning
to the value of a coherence state beyond upgrades or downgrades. Thus, how or
why a particular cache state implies that a particular address may not be
present in any other cache stems from protocol specific ``compatibility of
state'' check. 

The main contributions of this paper are: 1. A new abstract protocol that
satisfies two important invariants for distributed and hierarchal
message-passing protocols; 2. Instantiation of the abstract protocol to
implement four well-known protocols (MSI, MESI, MOSI, MOESI) and their
variations and showing why their correctness is guaranteed as long as the
abstract protocol is correct, \ie it provably implements the two invariants;
and 3. Our method does not introduce any overhead over direct implementation of
these protocols.  We think that this new method of designing protocols
substantially reduces the required effort, and that our abstract protocol is
flexible enough to implement (while ensuring correctness of) most if not all
inclusive message-passing directory-based protocols.

\paragraph{Paper organization:} Section \ref{sec:abstract} describes the abstract
protocol; Section \ref{sec:properties} gives the two properties that are
guaranteed by the abstract protocol and provides some intuition for proving
these properties. We also discuss the communication buffer requirements for the
abstract protocol and show that the requirement is only proportional to the
number of levels and not to the number of processors. In Section
\ref{sec:protocols}, we show how the abstract protocol can be used to implement
MSI, MESI, MOSI and MOESI protocols and their variants. In Section
\ref{sec:performance}, we show that these formally verified family of protocols
require no extra state bits, nor extra message transfers compared to other
published implementations. In Section \ref{sec:related}, we present some of the
related work and finally in Section \ref{sec:conclusion}, we present some
directions for the future work.
