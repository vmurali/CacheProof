\section{Distributed MSI}
\label{sec:DistributedMsi}


In order to transfer the Global MSI protocol into a distribute MSI protocol, we
need to make sure that a method can only read and write the state of the cache
with which the method is associated, and it affects the state of other caches
only by sending messages. In order to read the state of a child's cache we
maintain a shadow state of in the form of a directory. Thus the coherence state
of a cache $c$, in addition to the $c.state[a]$ field, also contains a
directory field containing the shadow state of each child's state field, \ie,
$c.dir[c'][a]$, for child $c'$.

We extend our sequential language for writing methods with two communication
primitives: \send{} $(Req|Resp|Data)\langle c_1 \rightarrow c_2, a,
(x|data)\rangle$ and \receive{} $(Req|Resp|Data)(\langle c_1 \rightarrow c_2,
a, (x|data)\rangle$ where caches $c_1$ and $c_2$ must satisfy the parent-child
relation. Both of these primitives are \emph{blocking}, that is, \send{} may
block because the network is clogged, \ie, has no buffer space to hold a
message and a \receive{} may block because the message has not arrived or cache
has no resources to process it. These primitives make our sequential language
methods ``suspensive'. Request or response messages have very different
characteristics and a data message is conceptually always associated with some
response message. We think of each \textsc{coreReq} as launching a thread in
L1. This thread in turn may get processed, send request or response messages,
may get suspended and eventually die. Thus potentially every request message
can launch a new thread in the cache that receives it. A response message,
however, can only die or generate more response messages; it can never generate
a request message. However a response message can also block waiting for the
corresponding data message. Each message and thread has an address associated
with it.

Though the threads are suspensive, the designer is given an illusion of the
threads being non-suspensive barring a few exceptions. In particular, the
\send{} and \receive{} operations can be considered as non-blocking operations
while designing the handlers for requests and responses. The exceptions that the
designer must be aware of which violates the illusion of non-suspensive threads
is as follows: ($this$ represents the cache under under consideration)

\begin{enumerate}
\item $this.dir[c][a]$ can keep decreasing while a thread corresponding to
address $a$ is executing.
\item $this.dir[c][a']$ can keep decreasing while a thread which is evicting
line $a'$ is executing.
\item If a thread receives responses from the parent, then $this.state[a]$ can
decrease between the operation of sending a request to the parent and the
operation of receiving a response from the parent.
\end{enumerate}

As can be seen, these interactions are minimal, and hence the correctness of
the protocol can be argued in terms of a single threaded, non-suspensive, execution model.
The formal proof for this, as well as the invariants stated below is beyond the
scope of this paper.

The designer must also be aware of the following:
\begin{enumerate}
\item There are 3 kinds of incoming messages to be handled: request from that parent,
requests from children and responses from children.
\item A downgrade-to-$x$ message might be received from the parent even if the
state of the cache is $ \le x$. This has to be handled.
\end{enumerate}

The designer can assume the following invariants regarding the directory and the state
of the children's caches:
\begin{theorem}
Conservative: For two nodes $p, c$, where $p = c.parent$, $\forall a,
p.dir[c][a] \ge c.state[a]$.  \label{conservative}
\end{theorem}

The reason why the designer can think a thread being non-suspensive because of
the following 4 invariants.

Regarding the \send{} and \receive{} operations, \ie the network, the designer
can assume the following:
\begin{theorem}
It a thread has to send a message, it will eventually be able to send the
message.
\label{canSend}
\end{theorem}

\begin{theorem}
If a cache sends an upgrade-to-$x$ request to its parent, it will eventually
get an upgrade-to-$y$ response from the parent where $y \ge x$.
\label{willRecv}
\end{theorem}

\begin{theorem}
If a cache sends an downgrade-to-$x$ request to one of its children, it will
eventually get a downgrade-to-$y$ response from the child where $y \le x$.
\label{willRecv2}
\end{theorem}

The following invariant ensures that a line can always be obtained for
replacement .
\begin{theorem}
If a thread is waiting for a line to be allocated, \ie for any address to become
available for eviction, then some address will eventually become available for
eviction
\label{evictDead}
\end{theorem}

All the complexity of suspending a thread, scheduling a thread, waking up a
thread, \etc are hidden from the designer.

Regarding the responses received, the designer can assume the following 2
invariants:

\begin{theorem}
If $p$ sends \Resp{p}{c}{a}{x} to $c$, where $p = c.parent$, then $p.dir[c][a]$
just before $p$ sends the response is the same as $c.state[a]$ just before $c$
receives the response.
\label{pcSame}
\end{theorem}

\begin{theorem}
If $c$ sends \Resp{c}{p}{a}{x} to $p$, where $p = c.parent$, then $c.state[a]$
just before $c$ sends the response is the same as $p.dir[c][a]$ just before $p$
receives the response.
\label{cpSame}
\end{theorem}

These invariants can be used by the designer to wait for receiving data messages
appropriately.


Our protocol also obeys the following properties:

We always reserve resources, \eg, cache line slot for an address before sending
an upgrade request for that address.
A second request is not sent for the same address from the same cache to the same
destination, until a response is received for the first request.

After the distributed protocol is designed, we
will show the bounds on the number of virtual channels to avoid head of the
line blocking and the minimum thread resource requirements to avoid deadlocks.



Figure \ref{msi-template} shows how the request handler methods \uReq{} and
\dReq{} can be refactored to make it amenable to distributed implementation. The
upgrade and downgrade request handlers are not allowed to invoke other cache's
upgrade or downgrade request handlers, or change other cache's states. Instead,
the same calls are made via 5 more local methods listed in Figure \ref{atomic}.
These methods in turn invoke the other caches upgrade and downgrade request
handlers, or change the states of other caches.

\begin{figure}
\small

\begin{subfigure}{\linewidth}
\begin{boxedminipage}{\linewidth}
\begin{algorithmic}
\Proc {\uReqL}{$p, a, x$}
  \State \send{} \Req{this}{p}{a}{x};
  \While {$this.state[a] < x$}
  \State \receive{} \Resp{p}{this}{a}{z};
  \If {$this.state[a] = I$}
    \State \receive{} \Data{p}{this}{a}{d};
    \State $this.data[a] \gets d$;
  \EndIf
  \State $this.state[a] \gets z$;
  \EndWhile
\EndProc
\end{algorithmic}
\end{boxedminipage}
\caption{Upgrading address $a$ of $this$ to $x$, by sending a request to
$this$'s parent $p$}
\label{uReqLocal}
\end{subfigure}

\begin{subfigure}{\linewidth}
\begin{boxedminipage}{\linewidth}
\begin{algorithmic}
\Proc {\dReqL}{$c, a, x$}
  \State \send{} \Req{this}{c}{a}{x};
  \While {$this.dir[c][a] > x$}
  \State \receive{} \Resp{c}{this}{a}{z};
  \If {$isModified(this.dir[c][a])$}
    \State \receive{} \Data{c}{this}{a}{d};
    \State $this.data[a] \gets d$;
  \EndIf
  \State $this.dir[c][a] \gets z$;
  \EndWhile
\EndProc
\end{algorithmic}
\end{boxedminipage}
\caption{Downgrading address $a$ of $this$'s child $c$ to $x$, by sending a
request to $c$}
\label{dReqLocal}
\end{subfigure}

\begin{subfigure}{\linewidth}
\begin{boxedminipage}{\linewidth}
\begin{algorithmic}
\Proc {\uResp}{$c, a, x$}
  \State \textbf{if} ($this.dir[c][a] = I$)
  \State \;\;\;\; \send{} \Data{this}{c}{a}{this.data[a]};
  \State $this.dir[c][a] \gets x$;
\EndProc
\end{algorithmic}
\end{boxedminipage}
\caption{$this$ finally upgrading address $a$ of its child $c$ to $x$, sending a
response to $c$ notifying of the upgrade and sending data to $c$ if necessary}
\label{uResp1}
\end{subfigure}

\begin{subfigure}{\linewidth}
\begin{boxedminipage}{\linewidth}
\begin{algorithmic}
\Proc {\dResp}{$p, a, x$}
  \State \textbf{if} ($isModified(this.state[a])$)
  \State \;\;\;\; \send{} \Data{this}{p}{a}{this.data[a]};
  \State $this.state[a] \gets x$;
\EndProc
\end{algorithmic}
\end{boxedminipage}
\caption{$this$ finally downgrading its state for address $a$ to $x$, sending a
response to $c$ notifying of the downgrade and sending data to $c$ if necessary}
\label{dResp1}
\end{subfigure}

\begin{subfigure}{\linewidth}
\begin{boxedminipage}{\linewidth}
\begin{algorithmic}
\Proc {\dRespL}{$c , a, x$}
  \If {$isModified(this.dir[c][a])$}
    \State \receive{} \Data{c}{this}{a}{d};
    \State $this.data[a] \gets d$;
  \EndIf
\EndProc
\end{algorithmic}
\end{boxedminipage}
\caption{$this$ handling unsolicited downgrade to $x$ response from $c$ for
address $a$. This happens if $c$ evicted address $a$}
\label{dRespL1}
\end{subfigure}

\begin{subfigure}{\linewidth}
\begin{boxedminipage}{\linewidth}
\begin{algorithmic}
\Proc {\sendMem{}}{$a$}
  \State \send{} \Req{this}{Memory}{a}{M};
  \State \receive{} \Data{Memory}{this}{a}{d};
  \State $this.data[a] \gets d$;
  \State $this.state[a] \gets M$;
\EndProc
\end{algorithmic}
\end{boxedminipage}
\caption{Last-Level-Cache $this$ sending and receivging data from memory for
address $a$}
\label{sendMem2}
\end{subfigure}

\caption{Non atomic implementation of MSI protocol}
\label{realistic}
\end{figure}

\subsection{Caches as a distributed system of multi-threaded execution engines}

The memory hierarchy in a processor can be specified as a collection of nodes
(Figure \ref{distNodes}). Each node has local state associated with it. The
state may contain the cache and the directory among other book-keeping
information. A node also has multiple input and multiple output channels
through which it can send and receive messages. Most of the channels are
connected to a network, which delivers messages between nodes
%; the message delivery order is left unspecified
. Some of the channels may not be connected to the network; they represent
inputs and outputs to the memory system, \viz the requests from and responses to
cores.

The behavior of each node can be best described as a system of suspendable local
threads, with a scheduler local to that node. A thread can be in one of the two
states: \emph{executing} or \emph{suspended}. At a given time, either one
thread or the scheduler will be executing. When the scheduler is executing,
it does one of the following: a) picks one of suspended threads
which has become ready to execute due to changed conditions or b) creates a new
thread to handle an incoming message. An executing thread can read the local
state of the node, send messages to output channels, receive messages from
input channels, \etc{}% or spawn more threads . The input and output channels are
blocking, so if a thread tries to send to a full output channel or receive from
an empty input channel, the thread would not be able to proceed. The thread can
also fail to proceed due to some condition in the local state of the node. In
all these cases, the thread gets suspended, giving back control to the
scheduler. It remains suspended till the required conditions are met (for
instance, the output channel becomes free, the input channel receives a
pertinent message, or other local state changes), Once the required conditions
for a suspended thread are met the scheduler may pick it for execution. The
execution is resumed from the exact point where it was suspended. Once the
thread finishes its execution, all the book-keeping resources associated with
that thread is freed up and reclaimed.

Incoming messages remain in the channel until they are explicitly removed by
the thread dealing with that message. If the scheduler sees an incoming message
that requires a new thread to be created for handling, and if the required
book-keeping resources are available, then a thread is created.
%Different threads require different amounts of book-keeping resources.
If the
required book-keeping resources are not available, the scheduler might pick
another suspended thread which is ready to execute, or if that's not possible,
spin-waits.  The threads and incoming messages have a memory address associated
with them. For an incoming message that does not require a new thread to be
created, its address is used by the scheduler to decide if a suspended thread
is ready to execute. Similarly, the address associated with a thread that has
just finished executing is used to determine if the local state of the node
associated with that address has changed so that a suspended thread associated
with that address can resume execution.  

Note that the thread analogy we described above has nothing to do with software
threads. We are describing the behavior of a cache controller using the familiar
notion of suspendable threads. The threads essentially correspond to the various
requests being handled by a cache controller's Miss Status Handler Register
(MSHR).

\begin{figure}
\begin{tabularx}{\linewidth}{|l|X|}
\hline
\send{} $m$ & Send a message $m$ to the node's output channel. This action
blocks till the channel has space to send.\\
\receive{} $m$ & Receive and remove a message $m$ from the node's input channel.
This action blocks till a message is received.\\
$x \gets value$ & Local state $x$ of the node gets updates to $value$.\\
%\call{} $f(args)$ & Execute \textbf{procedure} $f$ with $args$ arguments.\\
%\start{} $f(args)$ & Start a new thread that executes \textbf{procedure} $f$
%with $args$ arguments. This action is performed only by the scheduler.\\
\resume{} $t$ & Resume thread $t$ from where it stopped execution. This action
is performed only by the scheduler\\
\hline
\end{tabularx}
\caption{Actions used for describing a node's behavior}
\label{actions}
\end{figure}

When a new message arrives in an input channel that requires creation of a
thread, the scheduler first removes the message from the channel and then
creates a thread that starts executing the \procedure{} specific to the type of
the incoming message. Figure \ref{actions} show the notations we use to
describe the actions performed by an executing thread. Procedures can call
other procedures but they can not be recursive. We usually denote the execution
of actions \receive{} and \send{} using their verb forms, for instance,
,``receiving'' or ``sending''. We also denote the thread created by the
scheduler to handle an incoming message as the thread ``handling'' that
message.
